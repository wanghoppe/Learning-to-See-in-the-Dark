{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, scipy.io\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import rawpy\n",
    "import glob\n",
    "\n",
    "input_dir = './dataset/Sony/short/'\n",
    "gt_dir = './dataset/Sony/long/'\n",
    "checkpoint_dir = './checkpoint/Sony/'\n",
    "result_dir = './result_Sony/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATIO = 10\n",
    "INPUT_IMG = 'test_data/sony_a500_10.arw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x):\n",
    "    return tf.maximum(x * 0.2, x)\n",
    "\n",
    "\n",
    "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    deconv_output = tf.concat([deconv, x2], 3)\n",
    "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return deconv_output\n",
    "\n",
    "\n",
    "def network(input):\n",
    "    conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
    "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
    "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
    "\n",
    "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
    "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
    "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
    "\n",
    "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
    "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
    "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
    "\n",
    "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
    "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
    "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
    "\n",
    "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
    "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
    "\n",
    "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
    "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
    "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
    "\n",
    "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
    "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
    "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
    "\n",
    "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
    "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
    "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
    "\n",
    "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
    "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
    "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
    "\n",
    "    conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
    "    out = tf.depth_to_space(conv10, 2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./checkpoint/Sony/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/Sony/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "in_image = tf.placeholder(tf.float32, [None, Noneinput_full = np.expand_dims(pack_raw(raw), axis=0) * ratio, None, 4])\n",
    "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
    "out_image = network(in_image)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt:\n",
    "    print('loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "if not os.path.isdir(result_dir + 'final/'):\n",
    "    os.makedirs(result_dir + 'final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = rawpy.imread(INPUT_IMG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just post-processing the raw img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "# scale_full = np.expand_dims(np.float32(im/65535.0),axis = 0)*ratio\n",
    "scale_full = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "scale_full = scale_full[0, :, :, :]\n",
    "scale_full = scale_full * np.mean(gt_full) / np.mean(\n",
    "    scale_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to process the img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_full = np.expand_dims(pack_raw(raw), axis=0) * RATIO\n",
    "input_full = np.minimum(input_full, 1.0)\n",
    "output = sess.run(out_image, feed_dict={in_image: input_full})\n",
    "        output = np.minimum(np.maximum(output, 0), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
